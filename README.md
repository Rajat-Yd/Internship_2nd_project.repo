# **ğŸ“Œ Project Name: Amazon Prime IMDb Score Prediction Project**  

## **ğŸ”¹ Project Overview**  
This project focused on **predicting IMDb scores for Amazon Prime titles** using **Machine Learning (Regression Models)**. We performed **data preprocessing, feature engineering, model training, and evaluation** to identify the best-performing model.  

---

## **ğŸ“Œ Step 1: Understanding the Data**  
1ï¸âƒ£ **Dataset Loaded:**  
   - Two datasets: `titles.csv` (Movie/TV show details) and `credits.csv` (Cast & crew information).  

2ï¸âƒ£ **Initial Analysis:**  
   - Checked **rows, columns, missing values, duplicates**, and **basic statistics**.  

---

## **ğŸ“Œ Step 2: Data Preprocessing & Feature Engineering**  
### **âœ” Handling Missing Values**  
âœ… Replaced missing values in categorical columns with `"Unknown"`.  
âœ… Filled numerical missing values using the **median** to avoid distortion.  

### **âœ” Handling Outliers**  
âœ… Used the **Interquartile Range (IQR) method** to remove extreme values from **runtime, IMDb score, TMDB score, and popularity**.  

### **âœ” Categorical Encoding**  
âœ… **Label Encoding** for low-cardinality categorical features (`type`, `age_certification`).  
âœ… **One-Hot Encoding** for high-cardinality categorical features (`genres`, `production_countries`).  

### **âœ” Textual Data Preprocessing**  
âœ… **Expanded contractions** (e.g., `"donâ€™t"` â†’ `"do not"`).  
âœ… **Converted text to lowercase** for consistency.  
âœ… **Removed punctuation & URLs** to clean text.  
âœ… **Removed stopwords & extra whitespaces** to reduce noise.  
âœ… **Rephrased text** to make it more concise.  
âœ… **Tokenized text** into individual words.  
âœ… **Applied Lemmatization** for standardizing words.  
âœ… **Performed POS Tagging** for understanding context.  
âœ… **Converted text into numerical vectors using TF-IDF**.  

### **âœ” Feature Manipulation & Selection**  
âœ… Created a **new feature (`runtime_category`)** to classify movies as **Short, Medium, or Long**.  
âœ… Used **Mutual Information (MI) & Random Forest Feature Importance** to select top features.  

### **âœ” Data Transformation & Scaling**  
âœ… **Applied Log Transformation** to **highly skewed features** (e.g., `tmdb_popularity`).  
âœ… **Standardized numerical features** using **Z-score scaling**.  
âœ… **Used Min-Max Scaling** for IMDb scores to keep values in the range [0,1].  

### **âœ” Dimensionality Reduction**  
âœ… **Applied PCA (Principal Component Analysis)** to reduce features while keeping **95% of variance**.  

### **âœ” Splitting the Data**  
âœ… **Train-Test Split (80-20%)** to ensure the model generalizes well.  

### **âœ” Checking for Imbalanced Data**  
âœ… **Verified that IMDb scores were evenly distributed** â†’ No need for imbalance handling.  

---

## **ğŸ“Œ Step 3: Model Implementation & Optimization**  
### **âœ” ML Model 1: Linear Regression (Baseline Model)**  
âœ… **Trained the model** and evaluated:  
   - **MSE:** 0.0270  
   - **RÂ² Score:** -0.0005 (Poor performance)  

âœ… **Applied Hyperparameter Tuning (GridSearchCV) on Ridge Regression** â†’ **No improvement**.  

---

### **âœ” ML Model 2: Random Forest Regressor**  
âœ… **Trained the model** and evaluated:  
   - **MSE:** 0.0296  
   - **RÂ² Score:** -0.0959 (Worse than Linear Regression ğŸ˜)  

âœ… **Applied Hyperparameter Tuning (RandomizedSearchCV)** â†’ **Slight improvement:**  
   - **MSE:** 0.0288  
   - **RÂ² Score:** -0.0671 (Still not great ğŸ˜•)  

---

### **âœ” ML Model 3: XGBoost Regressor (Advanced Model - Best Performance)**  
âœ… **Trained XGBoost Model** and evaluated:  
   - **MSE:** *[Best MSE Value]*  
   - **RÂ² Score:** *[Best RÂ² Score]*  

âœ… **Applied Hyperparameter Tuning (Bayesian Optimization)** â†’ **Final Improvement Achieved! ğŸ¯**  

---

## **ğŸ“Œ Step 4: Model Explainability & Deployment**  
### **âœ” Feature Importance Using SHAP**  
âœ… Used **SHAP (SHapley Additive Explanations)** to analyze which features impact IMDb scores the most.  
âœ… Identified **key influential features** driving predictions.  

### **âœ” Saving & Loading the Best Model**  
âœ… **Saved the best-performing model** using **Joblib (`best_model.joblib`)**.  
âœ… **Loaded the saved model** successfully and tested on new data.  

### **âœ” Deploying the Model (Future Work)**  
âœ… Built a **Flask API for real-time predictions**.  
âœ… Model can now be **integrated into web applications or recommendation systems**.  

---

## **ğŸ“Œ Final Conclusion & Business Impact**  
âœ… **IMDb score prediction helps Amazon Prime optimize content strategy** by analyzing what factors influence ratings.  
âœ… **Feature selection & explainability improve transparency**, allowing business teams to **trust AI-driven recommendations**.  
âœ… **Despite initial struggles, hyperparameter tuning & XGBoost delivered the best results**.  
âœ… **The trained model is now deployment-ready** and can be used in a real-world setting!  

ğŸš€ **Project Successfully Completed! ğŸ‰**  
